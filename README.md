# ğŸ“˜ AI Handbook Generator (LightRAG + LongWriter)

An end-to-end AI engineering project that generates long-form handbooks (20,000+ words) from PDF documents using Retrieval-Augmented Generation (RAG), LightRAG-compatible architecture, Supabase vector storage, and a Hugging Face LLM.

This project was built as part of an AI Engineering assignment and focuses on system design, modularity, and long-form generation pipelines rather than model fine-tuning.

---

## ğŸš€ Key Features

- ğŸ“„ PDF upload and text extraction
- âœ‚ï¸ Chunking and semantic indexing
- ğŸ§  LightRAG-style retrieval using Supabase + pgvector
- ğŸ¤– Hugging Face LLM  for section writing
- ğŸ“ LongWriter-style iterative handbook generation
- ğŸ“˜ 20,000+ word handbook generation
- ğŸ’¬ Chat-based RAG interface (Streamlit)
- â¬‡ï¸ Exportable handbook (Markdown)

---

## ğŸ—ï¸ System Architecture

PDF Upload
â†“
Text Extraction (pdfplumber)
â†“
Chunking
â†“
Sentence-BERT Embeddings
â†“
Supabase Vector DB (pgvector)
â†“
LightRAG Retrieval
â†“
Hugging Face LLM (FLAN-T5)
â†“
LongWriter-style Iterative Loop
â†“
20,000+ Word Handbook



The retrieval and generation layers are fully decoupled, allowing easy replacement of models or vector stores.

---

## ğŸ§  Retrieval-Augmented Generation (RAG)

- Embeddings: `sentence-transformers/all-MiniLM-L6-v2`
- Vector store: Supabase PostgreSQL with `pgvector`
- Similarity search: cosine distance via SQL RPC
- Retrieval strategy: top-k semantic search

All generated content is grounded strictly in retrieved document context.

---

## âœï¸ LongWriter-Style Handbook Generation

The handbook generator follows a LongWriter-style architecture:

- Topic-based outline generation
- Section-by-section writing
- Iterative loop until target word count (20,000 words)
- Each section retrieves fresh context via LightRAG
- Hugging Face LLM rewrites retrieved context into coherent text

This design supports scalable long-form generation without relying on a single prompt.

---

## ğŸ› ï¸ Tech Stack

- **Language:** Python 3
- **UI:** Streamlit
- **PDF Processing:** pdfplumber
- **Embeddings:** Sentence-BERT
- **Vector DB:** Supabase + pgvector
- **LLM:** Hugging Face FLAN-T5 (local inference)
- **Environment:** python-dotenv

---

## â–¶ï¸ How to Run

### 1. Install dependencies
```bash
pip install -r requirements.txt

streamlit run app.py
python test_handbook.py

